{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c7d1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features after RFE: ['petal length (cm)' 'petal width (cm)']\n",
      "Selected Features after SelectKBest: ['petal length (cm)' 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Import  libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- RFE Example ---\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Use RFE to recursively eliminate features\n",
    "rfe = RFE(estimator=rf_classifier, n_features_to_select=2)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "\n",
    "# Print the selected features after RFE\n",
    "selected_features_rfe = np.array(iris.feature_names)[rfe.support_]\n",
    "print(\"Selected Features after RFE:\", selected_features_rfe)\n",
    "\n",
    "# --- SelectKBest Example ---\n",
    "# Use SelectKBest to select the top 2 features based on F-statistic\n",
    "kbest = SelectKBest(score_func=f_classif, k=2)\n",
    "X_train_kbest = kbest.fit_transform(X_train, y_train)\n",
    "\n",
    "# Print the selected features after SelectKBest\n",
    "selected_features_kbest = np.array(iris.feature_names)[kbest.get_support()]\n",
    "print(\"Selected Features after SelectKBest:\", selected_features_kbest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00f9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a8774bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfeFeature(indep_X, dep_Y, n):\n",
    "    rfelist = []\n",
    "\n",
    "    log_model = LogisticRegression(solver='lbfgs')\n",
    "    RF = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "    DT = DecisionTreeClassifier(criterion='gini', max_features='sqrt', splitter='best', random_state=0)\n",
    "    svc_model = SVC(kernel='linear', random_state=0)\n",
    "\n",
    "    rfemodellist = [log_model, svc_model, RF, DT]\n",
    "    for i in rfemodellist:\n",
    "        print(i)\n",
    "        log_rfe = RFE(i, n_features_to_select=n)\n",
    "        log_fit = log_rfe.fit(indep_X, dep_Y)\n",
    "        log_rfe_feature = log_fit.transform(indep_X)\n",
    "        rfelist.append((log_rfe_feature, log_fit, i))\n",
    "\n",
    "    return rfelist\n",
    "\n",
    "def split_scalar(indep_X,dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(indep_X,dep_Y, test_size = 0.25, random_state = 0)\n",
    "        \n",
    "        #Feature Scaling\n",
    "        #from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def cm_prediction(classifier,X_test):\n",
    "     y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Making the Confusion Matrix\n",
    "     from sklearn.metrics import confusion_matrix\n",
    "     cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     from sklearn.metrics import accuracy_score \n",
    "     from sklearn.metrics import classification_report \n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "        #cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     Accuracy=accuracy_score(y_test, y_pred )\n",
    "        \n",
    "     report=classification_report(y_test, y_pred)\n",
    "     return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "\n",
    "\n",
    "def logistic(X_train, y_train, X_test):\n",
    "    classifier = LogisticRegression(random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Extracting feature importance for Logistic Regression\n",
    "    feature_importance = classifier.coef_[0]\n",
    "\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = cm_prediction(classifier, X_test)\n",
    "    return classifier, Accuracy, report, X_test, y_test, cm, feature_importance\n",
    "\n",
    "\n",
    "def random(X_train, y_train, X_test):\n",
    "    classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Extracting feature importance for Random Forest\n",
    "    feature_importance = classifier.feature_importances_\n",
    "\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = cm_prediction(classifier, X_test)\n",
    "    return classifier, Accuracy, report, X_test, y_test, cm, feature_importance\n",
    "\n",
    "\n",
    "def Decision(X_train, y_train, X_test):\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Extracting feature importance for Decision Tree\n",
    "    feature_importance = classifier.feature_importances_\n",
    "\n",
    "    classifier, Accuracy, report, X_test, y_test, cm = cm_prediction(classifier, X_test)\n",
    "    return classifier, Accuracy, report, X_test, y_test, cm, feature_importance\n",
    "\n",
    "\n",
    "def rfe_classification(acclog, accrf, accdes, feature_importance_logistic, feature_importance_rf, feature_importance_decision):\n",
    "    rfedataframe = pd.DataFrame(index=['Logistic', 'Random', 'DecisionTree'],\n",
    "                                columns=['Accuracy', 'Feature_Importance'])\n",
    "\n",
    "    for number, idex in enumerate(rfedataframe.index):\n",
    "        rfedataframe['Accuracy'][idex] = [acclog[number], accrf[number], accdes[number]]\n",
    "        rfedataframe['Feature_Importance'][idex] = [feature_importance_logistic[number],\n",
    "                                                     feature_importance_rf[number],\n",
    "                                                     feature_importance_decision[number]]\n",
    "\n",
    "    return rfedataframe\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a50b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=pd.read_csv(\"prep.csv\",index_col=None)\n",
    "df2=dataset1\n",
    "df2 = pd.get_dummies(df2, drop_first=True)\n",
    "\n",
    "indep_X=df2.drop('classification_yes', 1)\n",
    "dep_Y=df2['classification_yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "526241fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arun\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Arun\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Arun\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Arun\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Arun\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Arun\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Arun\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Arun\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Arun\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Arun\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\Users\\Arun\\anaconda3\\envs\\aiml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(kernel='linear', random_state=0)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "DecisionTreeClassifier(max_features='sqrt', random_state=0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of using the modified functions\n",
    "rfelist = rfeFeature(indep_X, dep_Y, 4)\n",
    "\n",
    "acclog = []\n",
    "accrf = []\n",
    "accdes = []\n",
    "feature_importance_logistic = []\n",
    "feature_importance_rf = []\n",
    "feature_importance_decision = []\n",
    "\n",
    "for i in rfelist:\n",
    "    X_train, X_test, y_train, y_test = split_scalar(i[0], dep_Y)\n",
    "\n",
    "    # Extract feature importance for Logistic Regression\n",
    "    logistic_classifier = i[2]\n",
    "    if isinstance(logistic_classifier, LogisticRegression):\n",
    "        classifier, Accuracy, report, X_test, y_test, cm, importance_logistic = logistic(X_train, y_train, X_test)\n",
    "        acclog.append(Accuracy)\n",
    "        feature_importance_logistic.append(importance_logistic)\n",
    "    else:\n",
    "        acclog.append(None)\n",
    "        feature_importance_logistic.append(None)\n",
    "\n",
    "    # Extract feature importance for Random Forest\n",
    "    rf_classifier = i[2]\n",
    "    if isinstance(rf_classifier, RandomForestClassifier):\n",
    "        classifier, Accuracy, report, X_test, y_test, cm, importance_random = random(X_train, y_train, X_test)\n",
    "        accrf.append(Accuracy)\n",
    "        feature_importance_rf.append(importance_random)\n",
    "    else:\n",
    "        accrf.append(None)\n",
    "        feature_importance_rf.append(None)\n",
    "\n",
    "    # Extract feature importance for Decision Tree\n",
    "    dt_classifier = i[2]\n",
    "    if isinstance(dt_classifier, DecisionTreeClassifier):\n",
    "        classifier, Accuracy, report, X_test, y_test, cm, importance_decision = Decision(X_train, y_train, X_test)\n",
    "        accdes.append(Accuracy)\n",
    "        feature_importance_decision.append(importance_decision)\n",
    "    else:\n",
    "        accdes.append(None)\n",
    "        feature_importance_decision.append(None)\n",
    "\n",
    "# You can access feature importance lists for each algorithm and each iteration: \n",
    "# feature_importance_logistic, feature_importance_rf, feature_importance_decision\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "780c9bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  \\\n",
      "Logistic      [0.95, None, None]   \n",
      "Random        [None, None, None]   \n",
      "DecisionTree  [None, 0.97, None]   \n",
      "\n",
      "                                             Feature_Importance  \n",
      "Logistic      [[2.030199866124361, 1.8843760679656576, 2.050...  \n",
      "Random                                       [None, None, None]  \n",
      "DecisionTree  [None, [0.10151051464073124, 0.289967813225265...  \n"
     ]
    }
   ],
   "source": [
    "# You can also create a dataframe to store the results\n",
    "result_df = rfe_classification(acclog, accrf, accdes, feature_importance_logistic, feature_importance_rf,\n",
    "                                feature_importance_decision)\n",
    "print(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
